{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parthket_cse555_finalreport.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwzrC+XiwHgEnyW8Ep/zIe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parthrjpt/EAS555_Projects/blob/main/parthket_cse555_finalreport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b66j29YkIQj6"
      },
      "source": [
        "# **Reliability of New Articles: Identifying Real and Fake News**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-AWdReQIe_r"
      },
      "source": [
        "##**Introduction**\n",
        "\n",
        "News Articles play an important role in our daily lives. They keep us updated regarding the daily proceedings around the world. They play an important role. For example, financial articles such as changes in stock market prices, articles on topics like cryptocurrency, or the federal budget, impact the common man. These help the common man to control their budget and think about their investments. News also conveys this information to various stakeholders such as local vendors, which control the rates of goods and services, which in turn impacts our regular life. News is also a medium of spreading social awareness not just locally but on a global scale. It tells us about the daily events that take place worldwide. Due to such an impact of news on human lives, we can agree with Edmund Burke, when he stated that the Fourth Estate, that of news, and media is far more important. It is also due to this importance it is much more vulnerable. Due to the emergence of various social media platforms, it is becoming more and more difficult to authenticate the source of news, making it much easier to fake it. A spread of such information, not only leads to confusion and chaos but also can lead to catastrophic losses, \n",
        "\n",
        "This problem statement of classifying fake/unreliable news articles apart from real/reliable news can be resolved with the help of various machine learning algorithms. A simple implementation of a decision tree or a binary classifier can be used provided the dataset is noise-free and annotated. This project report and the corresponding project intend to use a Passive-Aggressive classifier to provide an optimal solution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jX2gGLAIplV"
      },
      "source": [
        "### **DataSet**\n",
        "For this project, we will be utilizing the Fake News dataset which was published on Kaggle for an InClass Prediction Competition. It comprises 20800 training samples and around 5200 test samples provided in csv formats. There are 5 columns: id, title, author, test, label [1] : \n",
        "\n",
        "*   id: unique id for a news article\n",
        "*   title: the title of a news article\n",
        "*   author: author of the news article\n",
        "*   text: the text of the article; could be incomplete\n",
        "*   label: a label that marks the article as potentially unreliable \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpdCHSkKJ08Z",
        "outputId": "c668b411-0ae7-4f77-dbad-3ece691a3bd8"
      },
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!echo '{\"username\":\"parthketanrajput\",\"key\":\"fec6fb4996a62e180eda7488c75580c9\"}' > ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 19.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 22.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 24.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=0d06b85e692b0b75e19878cad082c57a1af6c6edc4a91f0493ed6b0ee65a2b9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhO6S8WpNNZ8",
        "outputId": "b82aff8d-cae8-4ba6-a9c9-270ad2e63d00"
      },
      "source": [
        "!kaggle competitions download -c fake-news"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading fake-news.zip to /content\n",
            " 88% 41.0M/46.5M [00:00<00:00, 28.0MB/s]\n",
            "100% 46.5M/46.5M [00:01<00:00, 48.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y1wOmOMNemw"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('./fake-news.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV7SGg1RJLHQ"
      },
      "source": [
        "##**Methods** \n",
        "The dataset is segregated into testing and training data.However, the test data is not annotated. The dataset was intended for competitive purposes to identify the optimal apporach for the problem statement. Therefore, the training data will be split for training and validation datasets. The dataset consists of two test features (i.e. title and text) of which the text feature is the major contributor for determining whether the article in question is reliable or not. The text feature contains a lot of irrelevant data, which should not be considered. This is because this data contains free-text  (which is understandable by humans but not by a machine). To resolve this issue, relevant words/terms need to be identified and irrelevant stop words must be removed. This is done with the help of tf-idf (term frequency/ inverse document frequency). Tf-idf is a statistical measure that identifies the relevancy of a term concerning a document. The term frequency is the number of occurrences of a term in a particular document. The inverse document frequency is the measure of occurrences of a term across a set of documents. Tf-idf provides a vectorized value that can be further utilized as features.\n",
        "For classification, a passive-aggressive approach is used. These approaches are usually implemented for large-scale learning [2]. Such algorithms are usually called ‘online learning’ algorithms, wherein the data is fed to the model sequentially instead of being fed as an entire batch. In these algorithms, if the prediction is correct then the model remains unchanged, else the model is updated.\n",
        " \n",
        "The trained model wis then used to predict the labels (denoting the reliability of the news articles). The accuracy of the model is defined with the help of a confusion matrix and accuracyscore since to indicate the actual number of correct classifications. \n",
        "\n",
        "The Passive agressive approach is also implemented with the help of countvectorization and the performance of both models is compared. Logistic regression is also used to determine output variables for validation data.\n",
        "\n",
        "Based on the comparitive performance of all three approaches, the approach with the highest accuracy is used for the predicting output variables for test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR6VC7OOszIB"
      },
      "source": [
        "### **Passive Agressive Classifiers**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfhkEDQzzN1J"
      },
      "source": [
        "For this project, Passive Aggressive CLassifier (PA) has been implemented. It is a family of online learning algorithms which can be used for binary and multiclass classification regression, etc.[3] This problem statement implemnts the Passive Agressive Classifier as a binary categorizer, that determines if a news article is authentic or not.\n",
        "\n",
        "Like every online algorithm, the PA Classifier follows a sequential approach. The algorithm will make a prediction like a binary classfier problem, it will receive a feedback and based on it, it may modify its prediction mechanism. \n",
        "\n",
        "The PA classifer, represents each instance as a vector and utilizes a decision boundary which modifies the state of the classifier.\n",
        "\n",
        "The algorithm for a binary classification problem will follow the following steps:\n",
        "*  Define an agressiveness paramter C>0\n",
        "*  Initialize weight w1= (0,....,0) \n",
        "*  For each example i.e ann(xi,yi) pair:\n",
        "    *  predict yt= sign(wt,xt)\n",
        "    *  Receive correct label and compute hinge loss\n",
        "    *  Define τ and update the weights for the next iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JIxsqvlOy0N"
      },
      "source": [
        "#import dependancies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import feature_extraction,pipeline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNfL9dfOOJQa"
      },
      "source": [
        "#Load dataset\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95AzSD26rCZW"
      },
      "source": [
        "#Identify missing data values\n",
        "missingdatacount = train_data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP9Vl4adrfLq",
        "outputId": "57a52b1e-26fe-467c-aee9-e183ca93e30f"
      },
      "source": [
        "missingdatacount"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id           0\n",
              "title      558\n",
              "author    1957\n",
              "text        39\n",
              "label        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MYPUhLZro69"
      },
      "source": [
        "#filling empty datavalues\n",
        "train_data = train_data.fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Ud02JHyJ-7"
      },
      "source": [
        "test_data = test_data.fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvDIqm4RVZnl"
      },
      "source": [
        "y=train_data.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVyAO3vxrBQS"
      },
      "source": [
        "#Splitting the dataset for trainng and validation purposes\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data['text'].astype(str), y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aHMjhF-AkiL"
      },
      "source": [
        "#The text field is the only field relevant for this implmentation\n",
        "X_test=test_data['text'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KGiWuA7ywuK",
        "outputId": "1ab1bba7-cbe9-4fb6-c371-6624b639ab5e"
      },
      "source": [
        "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16640,) (4160,) (16640,) (4160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj64K-XULtKj",
        "outputId": "4e7fa69e-4a2f-4430-b6fd-7db1584a2029"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17640    MONTAGUE, Mass.  —   Think of all the dogs out...\n",
              "14615    In his speech at Washington University, MILO c...\n",
              "2554     SEOUL, South Korea  —   It was supposed to be ...\n",
              "16550    Seven World-Historical 'Achievements' Of The I...\n",
              "3179     By Peter van Els, The Netherlands Many sometim...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIRi8Xh-NVVs",
        "outputId": "c11996f6-40f7-40f0-c4e2-bd5a2c5ddae7"
      },
      "source": [
        "# Download stopwords for english language\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFJgPLhyM7eV"
      },
      "source": [
        "corpus=set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBlKqMUn2cn2"
      },
      "source": [
        "#Remove stopwords\n",
        "data_train = [word for word in X_train if word not in (corpus)]\n",
        "data_val =  [word for word in X_val if word not in (corpus)]\n",
        "data_test= [word for word in X_test if word not in (corpus)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O35rrY33OZT1"
      },
      "source": [
        "# Utilizing TF-IDF Vectorization to identify relevant term frequencies in documents and replace them with a numerical equivalent value\n",
        "tfidf = feature_extraction.text.TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(data_train)\n",
        "tfidf_val = tfidf.transform(data_val)\n",
        "tfidf_test = tfidf.transform(data_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVRlZXRnzQqV"
      },
      "source": [
        "clf=PassiveAggressiveClassifier(max_iter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQJMgBKX0txa",
        "outputId": "71a82751-b17a-4ccc-90a2-7b03115ed106"
      },
      "source": [
        "clf.fit(tfidf_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
              "                            early_stopping=False, fit_intercept=True,\n",
              "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
              "                            n_jobs=None, random_state=None, shuffle=True,\n",
              "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpXbpy-s015W"
      },
      "source": [
        "y_pred_val1 = clf.predict(tfidf_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TtLCjMuKosb"
      },
      "source": [
        "#Alternatively using Count Vectorizer.\n",
        "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
        "cv_train = count_vectorizer.fit_transform(data_train)\n",
        "cv_val = count_vectorizer.transform(data_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N9AFtEyLyHy",
        "outputId": "6849316e-2fee-4aef-c6f7-a49e79583a3b"
      },
      "source": [
        "clf.fit(cv_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
              "                            early_stopping=False, fit_intercept=True,\n",
              "                            loss='hinge', max_iter=50, n_iter_no_change=5,\n",
              "                            n_jobs=None, random_state=None, shuffle=True,\n",
              "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
              "                            warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3RNKIMGCO_"
      },
      "source": [
        "y_pred_val2 = clf.predict(cv_val)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YmBiHMWCuiB"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lclf= LogisticRegression(max_iter=100)\n",
        "lclf.fit(tfidf_train,y_train)\n",
        "y_pred_lgr=lclf.predict(tfidf_val)\n",
        "\n",
        "clf= PassiveAggressiveClassifier(max_iter=50)\n",
        "clf.fit(tfidf_train,y_train)\n",
        "y_pred_test = clf.predict(tfidf_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g64WtU0zGLQr"
      },
      "source": [
        "##  **Results**\n",
        "\n",
        "The above implementation demostrates how the dataset has been fit on the model. The Passive aggressive classifer was implemented with both the Count vectorizer and  TF-IDF vectorizer. Based on the below performance measures, it can be said that TF-IDF has a much higher performance on the validation dataset. The model is then compared in similar settings with Logisitic regression on the same model. In this case as well, the Passive Aggressive Classifier performs better comparitively.\n",
        "\n",
        "Based on these results we utilize a similar approach we then classify the test dataset with a PA Model. Since this was dataset meant for competitive purposes, it lacks actual output variables for the test data and therefore the predicited results cannot be verified.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc6GBd9B7YJ8",
        "outputId": "04584d83-f66e-4b81-d757-619ca8ac2304"
      },
      "source": [
        "confusion_matrix(y_val,y_pred_val1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2000,   83],\n",
              "       [  76, 2001]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssgEaiIX7jpR",
        "outputId": "c9931982-e82a-47ab-b982-c3a882693bc6"
      },
      "source": [
        "confusion_matrix(y_val,y_pred_val2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1939,  144],\n",
              "       [ 150, 1927]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJwWpzOb7mli",
        "outputId": "a8fc0ed9-8172-4410-c992-61631ef76b76"
      },
      "source": [
        "accuracy_score(y_val,y_pred_val1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9617788461538461"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBPvoTQ29RwI",
        "outputId": "c503d1d0-8066-4d47-9fb9-ed07b3990983"
      },
      "source": [
        "accuracy_score(y_val,y_pred_val2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9293269230769231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpYBK5us_8B6",
        "outputId": "69a30833-776a-4c33-d372-7c217a1a5cdc"
      },
      "source": [
        "confusion_matrix(y_val,y_pred_lgr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1941,  142],\n",
              "       [ 114, 1963]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR62lh8sAEk8",
        "outputId": "2dee6dc0-e834-43d5-f3fe-82aa35f2af4e"
      },
      "source": [
        "accuracy_score(y_val,y_pred_lgr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9384615384615385"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjsdyZ2uBFIf",
        "outputId": "5c173e0d-084e-4113-f406-8ceae9598ed4"
      },
      "source": [
        "y_pred_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-elsiwLQJYOc"
      },
      "source": [
        "### **Citations**\n",
        " \n",
        "[1] Fake News Dataset ( https://www.kaggle.com/c/fake-news/overview/evaluation)<br/>\n",
        "[2] Passive Aggressive Classifiers (https://www.geeksforgeeks.org/passive-aggressive-classifiers/)</br>\n",
        "[3] Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online Passive-Aggressive Algorithms. J. Mach. Learn. Res. 7 (12/1/2006), 551–585.(https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1G8zUpnJAyU"
      },
      "source": [
        "# **Ethics in AI**\n",
        "\n",
        "## **Impact on the problem statement**\n",
        "AI is a major aspect of applications that vary across various areas of exterise globally. Some of these applications are as trivial as performing a google search, whereas others are as critical as identifying tumours and categrozing as malignant or benign for a patient. Due to this, the ethicality of the implementations is a critical factor that must be accounted for.\n",
        "\n",
        "Given that some of these applications, are critical and can lead to breach of trust, security hazards, financial losses, it is critical that standards and regulations be imposed and an awareness be raised among people.\n",
        "\n",
        "Consider the above problem statement for fake news, as it is already a known fact that data is the most significant component when it comes to AI. If the data is biased, then the results are also bound to be biased. SOurces of all over the internet can ideally be categorized as genuine or not. However, consider a scenario, wherein a reputated news agency becomes interested in increasing its viewership and tries to fabircate news or exagerrate it. In such a case, the article will even be able to fool a human. If such articles are fed to the training model, then there are bound to be faulty classifications. Since, news articles are a critical part of human society, conveying fake/unreliable articles to the people can have disastrous outcomes.\n",
        "\n",
        "In this scenario, a centralized governing body that authenticates all news sources and verifies them with other articles(major or minor) is necessary. If an inconsistency is observed, then the article must be investigated. Standard rules and regulations, and penalties can be imposed to ensure the autheticity and reliability of the data source.\n",
        "\n",
        "While only one aspect of maintaining Ethics in AI has been discussed, other aspects such as impact on privacy of the people should also be consideder.\n",
        "\n",
        "## **Impact on Employment**\n",
        "\n",
        "As previously mentioned, AI has a significant reach in every sector. In sectors like public safety, manufacturing, etc. which were once cosnidered as job profiles that require physical efforts, AI along with robotics has managed to replace the human factor, achieving much more efficiency. However, this also meant that a lot of these job profiles became obsolete and increase in  unemployment. The IT sector is also no exception to this change. A lot of software development organizations, are heavily integrating Ai to improve user experience in their products. However, they now also use Ai based tools for automation testing and unit testing. Due to this the industry has a lower demand for Quality Analysts/Testers in such organizations. It can be said that over the next few years, the job profile may become compeletely obsolete.\n",
        "\n",
        "While technological advancements are indeed a necessity, we also need to realise their indirect impact. In this case, an analysis of the implementation must be taken into consideration, and restrictions must be imposed on the extent to which job profiles can automated. Limitations to automation, can also be implemented, by raising awareness related to expenses, and ethicality of it. \n",
        "\n",
        "\n"
      ]
    }
  ]
}